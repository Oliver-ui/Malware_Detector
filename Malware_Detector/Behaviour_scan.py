import import_ipynb
import Feature_extraction as fe
import pandas as pd
import numpy as np
import os

class BehaviourScan(object):

	def __init__(self):
		self.tasks = []
		self.which_task = None
		self.target_path = "C:\\Users\\12051\\Desktop\\logfile.CSV"

	def get_result_features(self, file_nums):
		# Read the file behaviour 
		init_data = fe.get_initial_data(self.target_path)
		init_data_temp = init_data

		# Record all the child processes of every main process
		related_process_id = {}

		"""
		Use PID to find the child processes of main process by refering pid and parent pid
		Numbers of sample files means how many pids here. Use dictionary to record.
		Loop the data file several times(how many files) and find all related process each round.
		Delete all related rows in data file every round to make sure main_pid = init_data_temp['PID'].tolist()[0] works.
		"""
		for counter in range(file_nums):
			main_pid = init_data_temp['PID'].tolist()[0]
			print("-----")
			print(main_pid)
			related_process_id[main_pid] = None
			pids = []
			delete_rows = []

			for index, row in init_data_temp.iterrows():
				
				if row['Parent PID'] == main_pid or row['Parent PID'] in pids:
					if row['PID'] not in pids:
						pids.append(row['PID'])
					delete_rows.append(index)

				elif row['PID'] == main_pid:
					delete_rows.append(index)

				else:
					continue

			init_data_temp = init_data_temp.drop(delete_rows)
			related_process_id[main_pid] = pids

		print(related_process_id)

		# Get all pids of processes
		sample_ids = fe.get_samples(init_data)

		# Create a temporary dataframe to record extracted features
		result_data_temp = pd.DataFrame(index=sample_ids, columns=np.arange(424))
		result_data_temp.loc[:,:] = 0

		# Extract each kind of feature respectively and record them
		fe.extract_dll_info(init_data, result_data_temp, sample_ids)
		fe.extract_reg_info(init_data, result_data_temp)
		fe.extract_path_info(init_data, result_data_temp)

		"""
		Use the record dataframe above to find every child process of main process and combine their features together.
		For each main process, create a dataframe to save behaviour of every sub-process. 
		If one process has sub-process, sum their features up and assign the result into related main process according to dataframe index(pid).
		If process does not have sub-process, copy its behaviour in result_data_temp to result data.
		"""
		result_data = pd.DataFrame(index=related_process_id.keys(), columns=np.arange(424))
		result_data.loc[:,:] = 0

		for key in related_process_id.keys():
			related_process = related_process_id[key]

			if related_process == None:
				result_data.loc[key, :] = result_data_temp.loc[key, :]

			else:
				related_rows = pd.DataFrame(index=related_process, columns=np.arange(424))
				related_rows.loc[:,:] = 0

				for index, row in result_data_temp.iterrows():

					if index in related_process or index == key:
						related_rows.loc[index, :] = result_data_temp.loc[index, :]

					else:
						continue

				result_data.loc[key, :] = related_rows.apply(lambda x: x.sum())

		return result_data

	# Load trained model
	def get_trained_model(self):
		lin = fe.get_model()
		return lin

	# Get the prediction of each submitted file
	def get_prediction(self, lin, result_data):
		lin_pred = lin.predict(result_data)
		return lin_pred

